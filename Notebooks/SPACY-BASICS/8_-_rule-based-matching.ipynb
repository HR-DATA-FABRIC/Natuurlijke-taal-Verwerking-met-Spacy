{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4473e601-6330-4219-a1cb-d6931c44fb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why not just match based on regex?\n",
    "#  Compared to regular expressions, the matcher works with Doc and Token objects instead of only strings.\n",
    "#  It's also more flexible: you can search for texts but also other lexical attributes.\n",
    "# Why not just match based on regex?\n",
    "#  Compared to regular expressions, the matcher works with Doc and Token objects instead of only strings.\n",
    "#  It's also more flexible: you can search for texts but also other lexical attributes.\n",
    "#  You can even write rules that use the model's predictions.\n",
    "#  For example, find the word \"duck\" only if it's a verb, not a noun.\n",
    "\n",
    "# We can match on exact token texts:\n",
    "# [{'TEXT': 'iPhone'}, {'TEXT': 'X'}]\n",
    "\n",
    "# or match on lexical attributes, e.g. two tokens whose lowercase forms are \"iphone\" and \"x\"\n",
    "# [{'LOWER': 'iphone'}, {'LOWER': 'x'}]\n",
    "\n",
    "# we can also match based on attributes predicted by the model\n",
    "\n",
    "# [{'LEMMA': 'buy'}, {'POS\n",
    "\n",
    "import spacy\n",
    "\n",
    "# Import the Matcher\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Load a model and create the nlp object\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Initialize the matcher with the shared vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "\n",
    "# Add the pattern to the matcher\n",
    "pattern = [{'TEXT': 'iPhone'}, {'TEXT': 'X'}]\n",
    "\n",
    "# The parameters here are:\n",
    "# 1) a unique ID to identify which pattern is matched\n",
    "# 2) an optional callback\n",
    "# 3) the pattern itself\n",
    "matcher.add('IPHONE_PATTERN', [pattern])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e147151-fdb6-40e4-bcac-e03e3908f0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process some text\n",
    "doc = nlp(\"New iPhone X release date leaked\")\n",
    "\n",
    "# Call the matcher on the doc\n",
    "matches = matcher(doc)\n",
    "\n",
    "# The matcher returns a list of tuples.  Each tuple consists of three values:\n",
    "# 1) the match ID\n",
    "# 2) the start index\n",
    "# 3) the end index of the matched span.\n",
    "\n",
    "# This means we can iterate over the matches and create a Span object: a slice of the doc at the start and end index.\n",
    "\n",
    "# Call the matcher on the doc\n",
    "doc = nlp(\"New iPhone X release date leaked\")\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8b32066-9df7-4875-bee0-3f89d6c87925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhone X\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# When you call the matcher on a doc, it returns a list of tuples.\n",
    "# Each tuple consists of three values: the match ID, the start index and the end index of the matched span.\n",
    "# This means we can iterate over the matches and create a Span object: a slice of the doc at the start and end index.\n",
    "\n",
    "# Iterate over the matches\n",
    "for match_id, start, end in matches:\n",
    "    # Get the matched span\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)\n",
    "\n",
    "# Here's an example of a more complex pattern using lexical attributes.\n",
    "# We're looking for five tokens:\n",
    "# A token consisting of only digits.\n",
    "# Three case-insensitive tokens for \"fifa\", \"world\" and \"cup\".\n",
    "# And a token that consists of punctuation.\n",
    "# The pattern matches the tokens \"2018 FIFA World Cup:\".\n",
    "\n",
    "pattern = [\n",
    "    {'IS_DIGIT': True},\n",
    "    {'LOWER': 'fifa'},\n",
    "    {'LOWER': 'world'},\n",
    "    {'LOWER': 'cup'},\n",
    "    {'IS_PUNCT': True}\n",
    "]\n",
    "\n",
    "doc = nlp(\"2018 FIFA World Cup: France won!\")\n",
    "\n",
    "matcher.add('WORLDCUP_PATTERN', [pattern])\n",
    "\n",
    "matches = matcher(doc)\n",
    "\n",
    "matches\n",
    "\n",
    "# We can also match other token attributes\n",
    "\n",
    "love_pattern = [\n",
    "    {'LEMMA': 'love', 'POS': 'VERB'},\n",
    "    {'POS': 'NOUN'}\n",
    "]\n",
    "\n",
    "catdogdoc = nlp(\"I loved dogs but now I love cats more.\")\n",
    "\n",
    "matcher.add('LOVE_PATTERN', [love_pattern])\n",
    "\n",
    "matches = matcher(catdogdoc)\n",
    "\n",
    "# We can use operators and quantifiers too\n",
    "\n",
    "# Operators and quantifiers let you define how often a token should be matched. They can be added using the \"OP\" key.\n",
    "# Here, the \"?\" operator makes the determiner token optional, so it will match a token with the lemma \"buy\",\n",
    "# an optional article and a noun.\n",
    "\n",
    "# \"OP\" can have one of four values:\n",
    "#\n",
    "# An \"!\" negates the token, so it's matched 0 times.\n",
    "#\n",
    "# A \"?\" makes the token optional, and matches it 0 or 1 times.\n",
    "#\n",
    "# A \"+\" matches a token 1 or more times.\n",
    "#\n",
    "# And finally, an \"*\" matches 0 or more times.\n",
    "#\n",
    "# Operators can make your patterns a lot more powerful, but they also add more complexity â€“ so use them wisely.\n",
    "\n",
    "buy_pattern = [\n",
    "    {'LEMMA': 'buy'},\n",
    "    {'POS': 'DET', 'OP': '?'},  # optional: match 0 or 1 times\n",
    "    {'POS': 'NOUN'}\n",
    "]\n",
    "\n",
    "phone_doc = nlp(\"I bought a smartphone. Now I'm buying apps.\")\n",
    "\n",
    "matcher.add('BUY_PATTERN', [buy_pattern])\n",
    "\n",
    "matches = matcher(phone_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff36ce22-12fc-459b-9c94-5f15cddaea92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy-pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "e9ae0633d31f27bc4783a903d0c059afa18a9d7fac2fcc436f04793c1d5215e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
